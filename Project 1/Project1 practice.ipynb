{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f2e13e0-97d7-43d0-b9fd-c3b80e33455d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "\n",
    "import os\n",
    "\n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6102d1c4-c815-4be9-bd18-96e5957bbe8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading yellow_tripdata_2024-01.parquet from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet...\n",
      "Downloaded yellow_tripdata_2024-01.parquet\n",
      "Downloading yellow_tripdata_2024-02.parquet from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-02.parquet...\n",
      "Downloaded yellow_tripdata_2024-02.parquet\n",
      "Downloading yellow_tripdata_2024-03.parquet from https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-03.parquet...\n",
      "Downloaded yellow_tripdata_2024-03.parquet\n",
      "Downloading fhvhv_tripdata_2024-01.parquet from https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-01.parquet...\n",
      "Downloaded fhvhv_tripdata_2024-01.parquet\n",
      "Downloading fhvhv_tripdata_2024-02.parquet from https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-02.parquet...\n",
      "Downloaded fhvhv_tripdata_2024-02.parquet\n",
      "Downloading fhvhv_tripdata_2024-03.parquet from https://d37ci6vzurychx.cloudfront.net/trip-data/fhvhv_tripdata_2024-03.parquet...\n",
      "Downloaded fhvhv_tripdata_2024-03.parquet\n"
     ]
    }
   ],
   "source": [
    "TAXI_URL: str = \"https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "# Date range for filtering\n",
    "START_DATE = datetime(2024, 1, 1)\n",
    "END_DATE = datetime(2024, 3, 31)\n",
    "\n",
    "def get_taxi_html() -> str:\n",
    "    \"\"\"Fetch the HTML content of the taxi data page.\"\"\"\n",
    "    response = requests.get(TAXI_URL)\n",
    "    response.raise_for_status()\n",
    "    html = response.content\n",
    "    return html\n",
    "\n",
    "def find_taxi_parquet_links() -> List[str]:\n",
    "    \"\"\"Find links to Yellow Taxi and HVFHV Parquet files within the date range.\"\"\"\n",
    "    html = get_taxi_html()\n",
    "    soup = bs4.BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    # Find all <a> tags with relevant titles\n",
    "    yellow_a_tags = soup.find_all(\"a\", attrs={\"title\": \"Yellow Taxi Trip Records\"})\n",
    "    hvfhv_a_tags = soup.find_all(\"a\", href=re.compile(r\"fhvhv.*\\.parquet\", re.IGNORECASE))\n",
    "    \n",
    "    # Combine all links\n",
    "    all_a_tags = yellow_a_tags + hvfhv_a_tags\n",
    "    \n",
    "    # Extract href attributes and filter based on .parquet\n",
    "    parquet_links = [a[\"href\"].strip() for a in all_a_tags if \".parquet\" in (a.get(\"href\") or \"\")]\n",
    "    return filter_links_by_date(parquet_links)\n",
    "\n",
    "def filter_links_by_date(links: List[str]) -> List[str]:\n",
    "    \"\"\"Filter Parquet file links by date, retaining only those within the specified range.\"\"\"\n",
    "    filtered_links = []\n",
    "    date_pattern = re.compile(r\"_(\\d{4})-(\\d{2})\\.parquet\")\n",
    "    \n",
    "    for link in links:\n",
    "        match = date_pattern.search(link)\n",
    "        if match:\n",
    "            year, month = int(match.group(1)), int(match.group(2))\n",
    "            file_date = datetime(year, month, 1)\n",
    "            if START_DATE <= file_date <= END_DATE:\n",
    "                filtered_links.append(link)\n",
    "    \n",
    "    return filtered_links\n",
    "\n",
    "def download_files(links: List[str], folder_name: str) -> None:\n",
    "    \"\"\"Download files from a list of links and save them to the specified folder.\"\"\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "        \n",
    "    headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36\"}\n",
    "    \n",
    "    for link in links:\n",
    "        file_name = link.split(\"/\")[-1]\n",
    "        file_path = os.path.join(folder_name, file_name)\n",
    "        print(f\"Downloading {file_name} from {link}...\")\n",
    "        \n",
    "        # Request with headers to mimic a browser\n",
    "        response = requests.get(link, headers=headers)\n",
    "        response.raise_for_status()  # Check if download was successful\n",
    "        \n",
    "        with open(file_path, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"Downloaded {file_name}\")\n",
    "\n",
    "# Find and download filtered links\n",
    "filtered_links = find_taxi_parquet_links()\n",
    "download_files(filtered_links, \"taxi_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "68ad4016-33db-4f16-b7d4-062caf15ec55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  hvfhs_license_num dispatching_base_num originating_base_num  \\\n",
      "0            HV0003               B03404               B03404   \n",
      "1            HV0003               B03404               B03404   \n",
      "2            HV0003               B03404               B03404   \n",
      "3            HV0003               B03404               B03404   \n",
      "4            HV0003               B03404               B03404   \n",
      "\n",
      "     request_datetime   on_scene_datetime     pickup_datetime  \\\n",
      "0 2024-01-01 00:21:47 2024-01-01 00:25:06 2024-01-01 00:28:08   \n",
      "1 2024-01-01 00:10:56 2024-01-01 00:11:08 2024-01-01 00:12:53   \n",
      "2 2024-01-01 00:20:04 2024-01-01 00:21:51 2024-01-01 00:23:05   \n",
      "3 2024-01-01 00:35:46 2024-01-01 00:39:59 2024-01-01 00:41:04   \n",
      "4 2024-01-01 00:48:19 2024-01-01 00:56:23 2024-01-01 00:57:21   \n",
      "\n",
      "     dropoff_datetime  PULocationID  DOLocationID  trip_miles  ...  sales_tax  \\\n",
      "0 2024-01-01 01:05:39           161           158        2.83  ...       4.05   \n",
      "1 2024-01-01 00:20:05           137            79        1.57  ...       0.89   \n",
      "2 2024-01-01 00:35:16            79           186        1.98  ...       1.60   \n",
      "3 2024-01-01 00:56:34           234           148        1.99  ...       1.52   \n",
      "4 2024-01-01 01:10:02           148            97        2.65  ...       3.43   \n",
      "\n",
      "   congestion_surcharge  airport_fee  tips  driver_pay  shared_request_flag  \\\n",
      "0                  2.75          0.0   0.0       40.18                    N   \n",
      "1                  2.75          0.0   0.0        6.12                    N   \n",
      "2                  2.75          0.0   0.0        9.47                    N   \n",
      "3                  2.75          0.0   0.0       11.35                    N   \n",
      "4                  2.75          0.0   0.0       28.63                    N   \n",
      "\n",
      "   shared_match_flag  access_a_ride_flag  wav_request_flag wav_match_flag  \n",
      "0                  N                   N                 N              N  \n",
      "1                  N                   N                 N              N  \n",
      "2                  N                   N                 N              N  \n",
      "3                  N                   N                 N              N  \n",
      "4                  N                   N                 N              N  \n",
      "\n",
      "[5 rows x 24 columns]\n",
      "Index(['hvfhs_license_num', 'dispatching_base_num', 'originating_base_num',\n",
      "       'request_datetime', 'on_scene_datetime', 'pickup_datetime',\n",
      "       'dropoff_datetime', 'PULocationID', 'DOLocationID', 'trip_miles',\n",
      "       'trip_time', 'base_passenger_fare', 'tolls', 'bcf', 'sales_tax',\n",
      "       'congestion_surcharge', 'airport_fee', 'tips', 'driver_pay',\n",
      "       'shared_request_flag', 'shared_match_flag', 'access_a_ride_flag',\n",
      "       'wav_request_flag', 'wav_match_flag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_parquet(r\"C:\\Users\\sanch\\TOOLS for Analytics\\Project 1\\taxi_data\\fhvhv_tripdata_2024-01.parquet\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Display column names to understand the structure\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "39e8c818-e849-4f07-805a-af0b20fa26af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19663930\n"
     ]
    }
   ],
   "source": [
    "# check how many rows before Uber\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "6a7c47f0-585c-479a-a670-a6ae4b8a4005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fhvhv_tripdata_2024-01.parquet', 'fhvhv_tripdata_2024-02.parquet', 'fhvhv_tripdata_2024-03.parquet']\n"
     ]
    }
   ],
   "source": [
    "# Define the folder path containing your Parquet files\n",
    "folder_path = r\"C:\\Users\\sanch\\TOOLS for Analytics\\Project 1\\taxi_data\"\n",
    "\n",
    "# Define the regex pattern to find files that contain \"fhvhv\" and end with \".parquet\"\n",
    "pattern = re.compile(r\".*fhvhv.*\\.parquet$\", re.IGNORECASE)\n",
    "\n",
    "# List all the Parquet files that match the pattern\n",
    "parquet_files = [f for f in os.listdir(folder_path) if pattern.match(f)]\n",
    "\n",
    "# Display the filtered file paths\n",
    "print(parquet_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd82e148-d817-49e6-80d0-c76f537bf8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e8fdab20-b5c1-4500-95ca-8b343280d40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [hvfhs_license_num, dispatching_base_num, originating_base_num, request_datetime, on_scene_datetime, pickup_datetime, dropoff_datetime, PULocationID, DOLocationID, trip_miles, trip_time, base_passenger_fare, tolls, bcf, sales_tax, congestion_surcharge, airport_fee, tips, driver_pay, shared_request_flag, shared_match_flag, access_a_ride_flag, wav_request_flag, wav_match_flag]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 24 columns]\n",
      "Index(['hvfhs_license_num', 'dispatching_base_num', 'originating_base_num',\n",
      "       'request_datetime', 'on_scene_datetime', 'pickup_datetime',\n",
      "       'dropoff_datetime', 'PULocationID', 'DOLocationID', 'trip_miles',\n",
      "       'trip_time', 'base_passenger_fare', 'tolls', 'bcf', 'sales_tax',\n",
      "       'congestion_surcharge', 'airport_fee', 'tips', 'driver_pay',\n",
      "       'shared_request_flag', 'shared_match_flag', 'access_a_ride_flag',\n",
      "       'wav_request_flag', 'wav_match_flag'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# check wether there is Non Uber Data in hour folder\n",
    "df = pd.read_parquet(r\"C:\\Users\\sanch\\TOOLS for Analytics\\Project 1\\taxi_data\\fhvhv_tripdata_2024-01.parquet\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Display column names to understand the structure\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07aa22f1-0fee-4837-9103-b05af940b90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "TLC_URL = \"https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "TAXI_ZONES_DIR = \"\"\n",
    "TAXI_ZONES_SHAPEFILE = f\"{TAXI_ZONES_DIR}/taxi_zones.shp\"\n",
    "WEATHER_CSV_DIR = \"\"\n",
    "\n",
    "CRS = 4326  # coordinate reference system\n",
    "\n",
    "# (lat, lon)\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "LGA_BOX_COORDS = ((40.763589, -73.891745), (40.778865, -73.854838))\n",
    "JFK_BOX_COORDS = ((40.639263, -73.795642), (40.651376, -73.766264))\n",
    "EWR_BOX_COORDS = ((40.686794, -74.194028), (40.699680, -74.165205))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3a11ef-75ee-4958-a138-8f34fefb8dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hi hi hi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb49eef9-bf05-479b-8f76-4f888b5aed27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
